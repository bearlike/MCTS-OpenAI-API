#!/usr/bin/env python3
# Pydantic Models for Chat Completion API
import time
from enum import Enum
from typing import List, Optional
from pydantic import BaseModel, Field, model_validator
from loguru import logger

CONTACT_US_MAP = {"Repository": "https://github.com/bearlike/mcts-openai-api"}


class ReasoningEffort(Enum):
    """
    - `low`- 2 iterations, 2 simulations per iteration, and 2 child nodes per parent (default).
    - `medium` - 3 iterations, 3 simulations per iteration, and 3 child nodes per parent.
    - `high` - 4 iterations, 4 simulations per iteration, and 4 child nodes per parent.
    """

    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


class ChatMessage(BaseModel):
    role: str
    content: str


class ChatCompletionRequest(BaseModel):
    """Creates a model response for the given chat conversation."""

    model: str = Field(..., description="The model used for the chat completion.")
    messages: List[ChatMessage]
    max_tokens: Optional[int] = Field(
        None,
        description="The maximum number of tokens that can be generated in the chat completion.",
    )
    temperature: Optional[float] = 0.7
    stream: Optional[bool] = False
    reasoning_effort: Optional[ReasoningEffort] = Field(
        ReasoningEffort.LOW,
        description="Constrains effort on reasoning. Currently supported values are `low`, `medium`, and `high`.",
    )


class ThinkingBlock(BaseModel):
    type: str = Field(
        default="thinking",
        description="The type of the thinking block. Always 'thinking'.",
    )
    thinking: str = Field(
        ...,
        description="The thinking content, always set equal to the message's reasoning_content.",
    )


class MessageModel(BaseModel):
    role: str = Field(
        default="assistant", description="The role of the message (e.g. 'assistant')."
    )
    reasoning_content: str = Field(
        ...,
        description="The reasoning content generated by the model. This value is duplicated in all thinking blocks.",
    )
    thinking_blocks: List[ThinkingBlock] = Field(
        default_factory=list,
        description="A list of thinking blocks. Each block's 'thinking' is synchronized with reasoning_content.",
    )
    content: str = Field(
        ..., description="The final main response content of the message."
    )

    @model_validator(mode="before")
    def auto_create_thinking_blocks(cls, values: dict) -> dict:
        """
        Pre-validation: If 'reasoning_content' is provided and no 'thinking_blocks' are supplied,
        automatically create a single thinking block with 'thinking' equal to 'reasoning_content'.
        """
        reasoning_content = values.get("reasoning_content")
        thinking_blocks = values.get("thinking_blocks")
        if reasoning_content and not thinking_blocks:
            values["thinking_blocks"] = [
                {"type": "thinking", "thinking": reasoning_content}
            ]
        return values

    def __setattr__(self, name, value):
        """
        Ensure that whenever the 'reasoning_content' or 'thinking_blocks' is updated,
        all thinking blocks have their 'thinking' field synchronized with reasoning_content.
        """
        super().__setattr__(name, value)
        if name in ("reasoning_content", "thinking_blocks"):
            if (
                "reasoning_content" in self.__dict__
                and "thinking_blocks" in self.__dict__
            ):
                for block in self.thinking_blocks:
                    block.thinking = self.reasoning_content


class ChoiceModel(BaseModel):
    finish_reason: str = Field(
        default="stop",
        description="The reason the model stopped generating tokens (e.g. 'stop').",
    )
    index: int = Field(
        default=0, description="The index of this choice in the list of choices."
    )
    message: MessageModel = Field(
        ..., description="A chat completion message generated by the model."
    )


class ChatCompletionResponse(BaseModel):
    """Represents a chat completion response returned by model, based on the provided input."""

    id: str = Field(
        default="mcts_response",
        description="A unique identifier for the chat completion.",
    )
    object: str = Field(
        default="chat.completion",
        description="The object type, which is always 'chat.completion'.",
    )
    created: float = Field(
        default_factory=time.time,
        description="The Unix timestamp (in seconds) of when the chat completion was created.",
    )
    model: str = Field(..., description="The model used for the chat completion.")
    choices: List[ChoiceModel] = Field(
        default_factory=list,
        description="A list of chat completion choices. Can be more than one if n is greater than 1.",
    )


# Example usage:
if __name__ == "__main__":
    chat = ChatCompletionResponse(
        model="openai/fake",
        choices=[
            ChoiceModel(
                message=MessageModel(
                    reasoning_content="example thinking response",
                    content="example main response",
                )
            )
        ],
    )
    # Convert to dict to get the desired JSON-like structure.
    logger.info(chat.model_dump())
